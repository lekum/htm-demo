{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "from collections import deque\n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "from nupic.data.inference_shifter import InferenceShifter\n",
    "from nupic.frameworks.opf.modelfactory import ModelFactory\n",
    "\n",
    "import model_params\n",
    "\n",
    "SECONDS_PER_STEP = 2\n",
    "WINDOW = 60\n",
    "\n",
    "output_notebook()\n",
    "fig = figure(title='CPU prediction example', y_range=(0,100))\n",
    "fig.xaxis.axis_label = \"time [s]\"\n",
    "fig.yaxis.axis_label = \"CPU usage [%]\"\n",
    "# Keep the last WINDOW predicted and actual values for plotting.\n",
    "actual_history = deque([0.0] * WINDOW, maxlen=60)\n",
    "prediction_history = deque([0.0] * WINDOW, maxlen=60)\n",
    "\n",
    "# Initialize the plot lines that we will update with each new record.\n",
    "actual_line = fig.line(range(WINDOW), actual_history, color='blue', legend='History', line_width=5)\n",
    "prediction_line = fig.line(range(WINDOW), prediction_history, color='red', legend='Prediction', line_width=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_cpu():\n",
    "  \"\"\"Poll CPU usage, make predictions, and plot the results. Runs forever.\"\"\"\n",
    "  # Create the model for predicting CPU usage.\n",
    "  model = ModelFactory.create(model_params.MODEL_PARAMS)\n",
    "  model.enableInference({'predictedField': 'cpu'})\n",
    "  # The shifter will align prediction and actual values.\n",
    "  shifter = InferenceShifter()\n",
    "\n",
    "  while True:\n",
    "    s = time.time()\n",
    "\n",
    "    # Get the CPU usage.\n",
    "    cpu = psutil.cpu_percent()\n",
    "\n",
    "    # Run the input through the model and shift the resulting prediction.\n",
    "    modelInput = {'cpu': cpu}\n",
    "    result = shifter.shift(model.run(modelInput))\n",
    "\n",
    "    # Update the trailing predicted and actual value deques.\n",
    "    inference = result.inferences['multiStepBestPredictions'][5]\n",
    "    if inference is not None:\n",
    "      actual_history.append(result.rawInput['cpu'])\n",
    "      prediction_history.append(inference)\n",
    "      actual_line.data_source.data[\"y\"] = actual_history\n",
    "      prediction_line.data_source.data[\"y\"] = prediction_history\n",
    "      push_notebook(handle=h)\n",
    "    time.sleep(SECONDS_PER_STEP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = show(fig, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "run_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_num():\n",
    "  \"\"\"Fake CPU with an ever increasing integer.\"\"\"\n",
    "  # Create the model for predicting CPU usage.\n",
    "  model = ModelFactory.create(model_params.MODEL_PARAMS)\n",
    "  model.enableInference({'predictedField': 'cpu'})\n",
    "  # The shifter will align prediction and actual values.\n",
    "  shifter = InferenceShifter()\n",
    "\n",
    "  for i in range(100):\n",
    "    s = time.time()\n",
    "\n",
    "    # Get the CPU usage.\n",
    "    cpu = i\n",
    "\n",
    "    # Run the input through the model and shift the resulting prediction.\n",
    "    modelInput = {'cpu': cpu}\n",
    "    result = shifter.shift(model.run(modelInput))\n",
    "\n",
    "    # Update the trailing predicted and actual value deques.\n",
    "    inference = result.inferences['multiStepBestPredictions'][5]\n",
    "    if inference is not None:\n",
    "      actual_history.append(result.rawInput['cpu'])\n",
    "      prediction_history.append(inference)\n",
    "      actual_line.data_source.data[\"y\"] = actual_history\n",
    "      prediction_line.data_source.data[\"y\"] = prediction_history\n",
    "      push_notebook(handle=h)\n",
    "    time.sleep(SECONDS_PER_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
